"""
–ü—Ä–∞–∫—Ç–∏—á–Ω–µ –∑–∞–Ω—è—Ç—Ç—è 4-4: –û—Å–Ω–æ–≤–∏ –≤–µ–±-—Å–∫—Ä–∞–ø—ñ–Ω–≥—É
–ü—Ä–∏–∫–ª–∞–¥ 1: –û—Å–Ω–æ–≤–∏ BeautifulSoup —Ç–∞ CSS —Å–µ–ª–µ–∫—Ç–æ—Ä–∏

–ê–≤—Ç–æ—Ä: –ö—É—Ä—Å Python –¥–ª—è –∫—ñ–±–µ—Ä–±–µ–∑–ø–µ–∫–∏
"""

from bs4 import BeautifulSoup
import requests
from typing import List, Dict


def example_1_basic_parsing():
    """–ü—Ä–∏–∫–ª–∞–¥ 1: –ë–∞–∑–æ–≤–∏–π –ø–∞—Ä—Å–∏–Ω–≥ HTML"""
    print("\n" + "="*70)
    print("–ü–†–ò–ö–õ–ê–î 1: –ë–∞–∑–æ–≤–∏–π –ø–∞—Ä—Å–∏–Ω–≥ HTML")
    print("="*70)
    
    html_doc = """
    <html>
    <head><title>–ù–æ–≤–∏–Ω–∏ –∫—ñ–±–µ—Ä–±–µ–∑–ø–µ–∫–∏</title></head>
    <body>
        <header>
            <h1>–ì–æ–ª–æ–≤–Ω—ñ –Ω–æ–≤–∏–Ω–∏</h1>
            <nav>
                <ul>
                    <li><a href="/news">–ù–æ–≤–∏–Ω–∏</a></li>
                    <li><a href="/blog">–ë–ª–æ–≥</a></li>
                </ul>
            </nav>
        </header>
        
        <main>
            <article class="news-article" id="article-1">
                <h2>–ù–æ–≤–∞ –≤—Ä–∞–∑–ª–∏–≤—ñ—Å—Ç—å —É Windows</h2>
                <p class="author">–ê–≤—Ç–æ—Ä: –Ü–≤–∞–Ω –ü–µ—Ç—Ä–µ–Ω–∫–æ</p>
                <p class="date">2025-11-04</p>
                <div class="content">
                    <p>Microsoft –≤–∏–ø—É—Å—Ç–∏–ª–∞ –ø–∞—Ç—á –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω–æ—ó –≤—Ä–∞–∑–ª–∏–≤–æ—Å—Ç—ñ...</p>
                </div>
                <div class="tags">
                    <span class="tag">Windows</span>
                    <span class="tag">Security</span>
                </div>
            </article>
            
            <article class="news-article" id="article-2">
                <h2>Ransomware –∞—Ç–∞–∫–∞ –Ω–∞ –∫–æ–º–ø–∞–Ω—ñ—é</h2>
                <p class="author">–ê–≤—Ç–æ—Ä: –ú–∞—Ä—ñ—è –ö–æ–≤–∞–ª–µ–Ω–∫–æ</p>
                <p class="date">2025-11-03</p>
                <div class="content">
                    <p>–í–µ–ª–∏–∫–∞ –∫–æ—Ä–ø–æ—Ä–∞—Ü—ñ—è —Å—Ç–∞–ª–∞ –∂–µ—Ä—Ç–≤–æ—é ransomware...</p>
                </div>
                <div class="tags">
                    <span class="tag">Ransomware</span>
                    <span class="tag">Incident</span>
                </div>
            </article>
        </main>
        
        <footer>
            <p>&copy; 2025 –ù–æ–≤–∏–Ω–∏ –±–µ–∑–ø–µ–∫–∏</p>
        </footer>
    </body>
    </html>
    """
    
    soup = BeautifulSoup(html_doc, 'html.parser')
    
    # 1. –ü–æ—à—É–∫ –∑–∞ —Ç–µ–≥–æ–º
    print("\n1Ô∏è‚É£  –ü–æ—à—É–∫ –∑–∞ —Ç–µ–≥–æ–º:")
    title = soup.find('title')
    print(f"   –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–æ—Ä—ñ–Ω–∫–∏: {title.text}")
    
    h1 = soup.find('h1')
    print(f"   –ì–æ–ª–æ–≤–Ω–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫: {h1.text}")
    
    # 2. –ü–æ—à—É–∫ –∑–∞ –∫–ª–∞—Å–æ–º
    print("\n2Ô∏è‚É£  –ü–æ—à—É–∫ –∑–∞ –∫–ª–∞—Å–æ–º:")
    first_article = soup.find('article', class_='news-article')
    print(f"   –ü–µ—Ä—à–∞ —Å—Ç–∞—Ç—Ç—è: {first_article.find('h2').text}")
    
    # 3. –ü–æ—à—É–∫ –≤—Å—ñ—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤
    print("\n3Ô∏è‚É£  –ü–æ—à—É–∫ –≤—Å—ñ—Ö —Å—Ç–∞—Ç–µ–π:")
    all_articles = soup.find_all('article', class_='news-article')
    for i, article in enumerate(all_articles, 1):
        h2 = article.find('h2')
        author = article.find('p', class_='author')
        print(f"   {i}. {h2.text}")
        print(f"      {author.text}")
    
    # 4. CSS —Å–µ–ª–µ–∫—Ç–æ—Ä–∏
    print("\n4Ô∏è‚É£  CSS —Å–µ–ª–µ–∫—Ç–æ—Ä–∏:")
    
    # –°–µ–ª–µ–∫—Ç–æ—Ä –∑–∞ ID
    article_1 = soup.select_one('#article-1')
    print(f"   –°—Ç–∞—Ç—Ç—è #article-1: {article_1.find('h2').text}")
    
    # –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–π —Å–µ–ª–µ–∫—Ç–æ—Ä
    tags = soup.select('article .tag')
    print(f"   –í—Å—ñ —Ç–µ–≥–∏:")
    for tag in tags:
        print(f"      - {tag.text}")
    
    # –Ü—î—Ä–∞—Ä—Ö—ñ—á–Ω–∏–π —Å–µ–ª–µ–∫—Ç–æ—Ä
    nav_links = soup.select('nav ul li a')
    print(f"   –ù–∞–≤—ñ–≥–∞—Ü—ñ–π–Ω—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è:")
    for link in nav_links:
        print(f"      - {link.text} ({link.get('href')})")


def example_2_css_selectors():
    """–ü—Ä–∏–∫–ª–∞–¥ 2: –î–µ—Ç–∞–ª—å–Ω—ñ CSS —Å–µ–ª–µ–∫—Ç–æ—Ä–∏"""
    print("\n" + "="*70)
    print("–ü–†–ò–ö–õ–ê–î 2: –î–µ—Ç–∞–ª—å–Ω—ñ CSS —Å–µ–ª–µ–∫—Ç–æ—Ä–∏")
    print("="*70)
    
    html = """
    <div class="container">
        <ul id="security-list">
            <li class="critical">CVE-2025-0001: RCE —É nginx</li>
            <li class="high">CVE-2025-0002: XSS —É WordPress</li>
            <li class="medium">CVE-2025-0003: SQLi —É Joomla</li>
            <li class="low">CVE-2025-0004: Info Disclosure</li>
        </ul>
        
        <table class="vulnerability-table">
            <tr>
                <th>ID</th>
                <th>Severity</th>
                <th>Status</th>
            </tr>
            <tr>
                <td>CVE-2025-0001</td>
                <td class="severity critical">Critical</td>
                <td class="status patched">Patched</td>
            </tr>
            <tr>
                <td>CVE-2025-0002</td>
                <td class="severity high">High</td>
                <td class="status vulnerable">Vulnerable</td>
            </tr>
        </table>
    </div>
    """
    
    soup = BeautifulSoup(html, 'html.parser')
    
    print("\n1Ô∏è‚É£  –°–µ–ª–µ–∫—Ç–æ—Ä –∑–∞ –∞—Ç—Ä–∏–±—É—Ç–æ–º:")
    critical_items = soup.select('li.critical')
    print(f"   –ö—Ä–∏—Ç–∏—á–Ω—ñ –≤—Ä–∞–∑–ª–∏–≤–æ—Å—Ç—ñ:")
    for item in critical_items:
        print(f"      - {item.text}")
    
    print("\n2Ô∏è‚É£  –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–π —Å–µ–ª–µ–∫—Ç–æ—Ä:")
    vuln_cells = soup.select('td.status.vulnerable')
    print(f"   –í—Ä–∞–∑–ª–∏–≤—ñ —Å–∏—Å—Ç–µ–º–∏:")
    for cell in vuln_cells:
        # –ó–Ω–∞–π—Ç–∏ CVE ID –≤ —Ç–æ–º—É –∂ —Ä—è–¥–∫—É
        row = cell.parent
        cve_id = row.find('td').text
        print(f"      - {cve_id}: {cell.text}")
    
    print("\n3Ô∏è‚É£  –Ü—î—Ä–∞—Ä—Ö—ñ—á–Ω–∏–π —Å–µ–ª–µ–∫—Ç–æ—Ä:")
    table_rows = soup.select('table.vulnerability-table tr')
    print(f"   –í—Å—ñ —Ä—è–¥–∫–∏ —Ç–∞–±–ª–∏—Ü—ñ: {len(table_rows)}")
    
    print("\n4Ô∏è‚É£  –°–µ–ª–µ–∫—Ç–æ—Ä –Ω–∞—â–∞–¥–∫—ñ–≤:")
    all_in_container = soup.select('div.container *')
    print(f"   –í—Å—ñ—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ —É –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ñ: {len(all_in_container)}")


def example_3_navigation():
    """–ü—Ä–∏–∫–ª–∞–¥ 3: –ù–∞–≤—ñ–≥–∞—Ü—ñ—è –ø–æ DOM –¥–µ—Ä–µ–≤—É"""
    print("\n" + "="*70)
    print("–ü–†–ò–ö–õ–ê–î 3: –ù–∞–≤—ñ–≥–∞—Ü—ñ—è –ø–æ DOM –¥–µ—Ä–µ–≤—É")
    print("="*70)
    
    html = """
    <div class="report">
        <h2>–ó–≤—ñ—Ç –ø—Ä–æ —ñ–Ω—Ü–∏–¥–µ–Ω—Ç –±–µ–∑–ø–µ–∫–∏</h2>
        <div class="metadata">
            <span class="id">INC-2025-001</span>
            <span class="date">2025-11-04</span>
            <span class="severity critical">Critical</span>
        </div>
        <div class="description">
            <p>–í–∏—è–≤–ª–µ–Ω–æ –Ω–µ—Å–∞–Ω–∫—Ü—ñ–æ–Ω–æ–≤–∞–Ω–∏–π –¥–æ—Å—Ç—É–ø –¥–æ —Å–∏—Å—Ç–µ–º–∏.</p>
            <p>–ê—Ç–∞–∫–∞ –∑–¥—ñ–π—Å–Ω–µ–Ω–∞ —á–µ—Ä–µ–∑ –≤—Ä–∞–∑–ª–∏–≤—ñ—Å—Ç—å –≤–µ–±-–¥–æ–¥–∞—Ç–∫—É.</p>
        </div>
        <div class="actions">
            <button>–ó–∞–∫—Ä–∏—Ç–∏</button>
            <button>–ï—Å–∫–∞–ª—É–≤–∞—Ç–∏</button>
        </div>
    </div>
    """
    
    soup = BeautifulSoup(html, 'html.parser')
    
    # –ó–Ω–∞–π—Ç–∏ —Å—Ç–∞—Ä—Ç–æ–≤–∏–π –µ–ª–µ–º–µ–Ω—Ç
    report = soup.find('div', class_='report')
    
    print("\n1Ô∏è‚É£  –î–æ—á—ñ—Ä–Ω—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ (children):")
    for child in report.children:
        if child.name:  # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Ç–µ–∫—Å—Ç–æ–≤—ñ –≤—É–∑–ª–∏
            print(f"   - {child.name}: {child.get('class', ['no class'])}")
    
    print("\n2Ô∏è‚É£  –í—Å—ñ –Ω–∞—â–∞–¥–∫–∏ (descendants):")
    all_descendants = [d for d in report.descendants if d.name]
    print(f"   –í—Å—å–æ–≥–æ –Ω–∞—â–∞–¥–∫—ñ–≤: {len(all_descendants)}")
    
    print("\n3Ô∏è‚É£  –ë–∞—Ç—å–∫—ñ–≤—Å—å–∫–∏–π –µ–ª–µ–º–µ–Ω—Ç (parent):")
    metadata = soup.find('div', class_='metadata')
    print(f"   –ë–∞—Ç—å–∫–æ metadata: {metadata.parent.get('class')}")
    
    print("\n4Ô∏è‚É£  –°—É—Å—ñ–¥–Ω—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ (siblings):")
    description = soup.find('div', class_='description')
    next_elem = description.find_next_sibling()
    print(f"   –ù–∞—Å—Ç—É–ø–Ω–∏–π –ø—ñ—Å–ª—è description: {next_elem.get('class')}")
    
    prev_elem = description.find_previous_sibling()
    print(f"   –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –ø–µ—Ä–µ–¥ description: {prev_elem.get('class')}")


def example_4_attributes():
    """–ü—Ä–∏–∫–ª–∞–¥ 4: –†–æ–±–æ—Ç–∞ –∑ –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏"""
    print("\n" + "="*70)
    print("–ü–†–ò–ö–õ–ê–î 4: –†–æ–±–æ—Ç–∞ –∑ –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏")
    print("="*70)
    
    html = """
    <div class="links-section">
        <a href="https://nvd.nist.gov/" class="external" target="_blank">
            NVD Database
        </a>
        <a href="/internal/reports" class="internal">
            –í–Ω—É—Ç—Ä—ñ—à–Ω—ñ –∑–≤—ñ—Ç–∏
        </a>
        <img src="/images/logo.png" alt="Logo" width="100" height="50">
        <input type="text" name="search" placeholder="–ü–æ—à—É–∫ CVE..." required>
    </div>
    """
    
    soup = BeautifulSoup(html, 'html.parser')
    
    print("\n1Ô∏è‚É£  –û—Ç—Ä–∏–º–∞–Ω–Ω—è –∞—Ç—Ä–∏–±—É—Ç—ñ–≤:")
    links = soup.find_all('a')
    for link in links:
        href = link.get('href')
        text = link.text.strip()
        classes = link.get('class', [])
        print(f"   {text}:")
        print(f"      href: {href}")
        print(f"      classes: {classes}")
    
    print("\n2Ô∏è‚É£  –ê—Ç—Ä–∏–±—É—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è:")
    img = soup.find('img')
    print(f"   src: {img.get('src')}")
    print(f"   alt: {img.get('alt')}")
    print(f"   width: {img.get('width')}px")
    
    print("\n3Ô∏è‚É£  –ê—Ç—Ä–∏–±—É—Ç–∏ —Ñ–æ—Ä–º–∏:")
    input_field = soup.find('input')
    print(f"   type: {input_field.get('type')}")
    print(f"   name: {input_field.get('name')}")
    print(f"   placeholder: {input_field.get('placeholder')}")
    print(f"   required: {input_field.has_attr('required')}")
    
    print("\n4Ô∏è‚É£  –°–ª–æ–≤–Ω–∏–∫ –≤—Å—ñ—Ö –∞—Ç—Ä–∏–±—É—Ç—ñ–≤:")
    print(f"   {img.attrs}")


def example_5_extracting_data():
    """–ü—Ä–∏–∫–ª–∞–¥ 5: –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö"""
    print("\n" + "="*70)
    print("–ü–†–ò–ö–õ–ê–î 5: –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö")
    print("="*70)
    
    html = """
    <table class="vulnerability-list">
        <thead>
            <tr>
                <th>CVE ID</th>
                <th>Product</th>
                <th>Severity</th>
                <th>CVSS</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><a href="/cve/2025-0001">CVE-2025-0001</a></td>
                <td>Apache HTTP Server</td>
                <td class="critical">Critical</td>
                <td>9.8</td>
            </tr>
            <tr>
                <td><a href="/cve/2025-0002">CVE-2025-0002</a></td>
                <td>WordPress</td>
                <td class="high">High</td>
                <td>7.5</td>
            </tr>
            <tr>
                <td><a href="/cve/2025-0003">CVE-2025-0003</a></td>
                <td>MySQL</td>
                <td class="medium">Medium</td>
                <td>5.3</td>
            </tr>
        </tbody>
    </table>
    """
    
    soup = BeautifulSoup(html, 'html.parser')
    
    # –ü–∞—Ä—Å–∏–Ω–≥ —Ç–∞–±–ª–∏—Ü—ñ
    vulnerabilities = []
    
    table = soup.find('table', class_='vulnerability-list')
    rows = table.find('tbody').find_all('tr')
    
    for row in rows:
        cols = row.find_all('td')
        
        vuln = {
            'cve_id': cols[0].find('a').text,
            'link': cols[0].find('a').get('href'),
            'product': cols[1].text,
            'severity': cols[2].text,
            'severity_class': cols[2].get('class')[0],
            'cvss': float(cols[3].text)
        }
        
        vulnerabilities.append(vuln)
    
    print("\nüìä –í–∏—Ç—è–≥–Ω—É—Ç—ñ –¥–∞–Ω—ñ:")
    for vuln in vulnerabilities:
        print(f"\n   {vuln['cve_id']} - {vuln['product']}")
        print(f"      Severity: {vuln['severity']} (CVSS: {vuln['cvss']})")
        print(f"      Link: {vuln['link']}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    critical = [v for v in vulnerabilities if v['severity_class'] == 'critical']
    high = [v for v in vulnerabilities if v['severity_class'] == 'high']
    medium = [v for v in vulnerabilities if v['severity_class'] == 'medium']
    
    print(f"   Critical: {len(critical)}")
    print(f"   High: {len(high)}")
    print(f"   Medium: {len(medium)}")
    print(f"   Average CVSS: {sum(v['cvss'] for v in vulnerabilities) / len(vulnerabilities):.2f}")


def main():
    """–ó–∞–ø—É—Å–∫ –≤—Å—ñ—Ö –ø—Ä–∏–∫–ª–∞–¥—ñ–≤"""
    print("\n" + "="*70)
    print("üéì –û–°–ù–û–í–ò BEAUTIFULSOUP –¢–ê CSS –°–ï–õ–ï–ö–¢–û–†–ò")
    print("="*70)
    
    try:
        example_1_basic_parsing()
        example_2_css_selectors()
        example_3_navigation()
        example_4_attributes()
        example_5_extracting_data()
        
        print("\n" + "="*70)
        print("‚úÖ –í—Å—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ —É—Å–ø—ñ—à–Ω–æ –≤–∏–∫–æ–Ω–∞–Ω—ñ!")
        print("="*70)
        
    except Exception as e:
        print(f"\n‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ BeautifulSoup
    try:
        from bs4 import BeautifulSoup
    except ImportError:
        print("‚ùå –ü–æ–º–∏–ª–∫–∞: –ë—ñ–±–ª—ñ–æ—Ç–µ–∫–∞ BeautifulSoup –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
        print("–í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å —ó—ó –∫–æ–º–∞–Ω–¥–æ—é: pip install beautifulsoup4")
        exit(1)
    
    main()
